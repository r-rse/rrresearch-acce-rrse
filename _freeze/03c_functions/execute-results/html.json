{
  "hash": "eb800d55a5a64b670f6df29a2d6eb91b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Functions\"\n---\n\n\nAs we've mentioned, functions, and especially user built custom functions, are a key feature of R and are a really powerful of reducing code repetition.\n\n::: {.alert .alert-info}\n## Function basics\n\n**Functions allow us to:**\n\n-   incorporate sets of instructions that we want to use repeatedly\n-   contain complex code in a neat sub-program\n-   reduce opportunity for errors\n-   make code more readable\n\n**You can do anything with functions that you can do with vectors:**\n\n-   assign them to variables\n-   store them in lists\n-   pass them as arguments to other functions\n-   create them inside functions\n-   return them as the result of a function\n\n**In general, functions usually:** \n\n- accept parameters (arguments) <- `INPUT` \n- return value(s) <- `OUTPUT`\n\n:::\n\n## Elements of a function\n\nHere's a simple skeleton of a function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfunction_name <- function(arg1, arg2, ...) {\n  # Function body\n  # ...\n\n  output\n}\n```\n:::\n\n\n### Function name\n\nFunction names **should be as descriptive as possible and follow the same rules as variable names**.\n\nThey **should be concise, should ideally start with a verb and be written in lowercase**. If the function name consists of multiple words, it **should be separated by an underscore (`_`).**\n\nYou should avoid using names that are used elsewhere in R, such as `dir`, `function`, `plot`, etc\n\n### Arguments\n\nArguments are the **inputs that a function accepts**. They are **specified within the parentheses `()` and separated by commas.**\n\nFunctions can have **any number of arguments**. These can be **any R object:** numbers, strings, arrays, data frames, of even pointers to other functions; anything that is needed for the function to run.\n\nArguments can be of different types, including:\n\n-   **Required arguments**: These are arguments that must be provided when calling the function.\n-   **Default arguments**: These are arguments that have a default value and are optional. If not provided, the default value is used.\n\nAgain, use descriptive names for arguments.\n\n### Function Body\n\nThe **code between the `{}` brackets** is the **function body** and represents the **code run every time the function is called.**\n\nIt can include any valid R code, including assignments, control structures, and other function calls.\n\nIdeally functions are short and do just one thing.\n\n**All inputs required for computation in the body must be supplied as arguments.**\n\n### Simple example\n\nLet's write a simple function that takes two arguments `x` and `y` and adds them together.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd <- function(x, y) {\n  x + y\n}\n```\n:::\n\n\nLet's test it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 4\ny <- 2\nadd(x, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6\n```\n\n\n:::\n:::\n\n\nCool it works!\n\n### Return value\n\n**By default, the output of the last line of the code is evaluated is the value that will be returned by the function.**\n\nWe can override that default by using `return` to explicitly specify what is returned.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd <- function(x, y) {\n  x + y\n  return(NULL)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nadd(x, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\nIt is **not necessary that a function return anything**, for example a **function that makes a plot might not return anything**, whereas a function that does a mathematical operation might return a number, or a list.\n\n### Documentation\n\nIt is **good practice to include documentation comments** at the beginning of the function body. This should **describe what the function does, what arguments it accepts, and what it returns.**\n\nIn R, this can be done using **`roxygen` notation**, which is the **default method for documenting R code** and automatically producing help files in R packages.\n\n\n### Function Environment\n\n::: {.alert .alert-info}\n**Every time a function is called, a new environment is created to host execution.**\n\n-   Each invocation is **completely independent of previous ones**\n\n-   Variables used within are ***local***, e.g. their scope lies within - and is limited to - the function itself. They are therefore **invisible outside the function body**\n:::\n\nObjects required by the function will be sought first in the ***local environment***. If an argument specified in the function is missing, it will return an error, even if such an object exists in the global environment.\n\nObjects required by computation but not specified as function arguments will be sought in the containing environment iteratively until it reaches the ***global environment***. This can be a source of bugs when developing with an untidy global environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb <- 10\nf2 <- function(a) {\n  a + b\n}\nf2(a = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 20\n```\n\n\n:::\n\n```{.r .cell-code}\nrm(b) # remove object b\nf2(a = 10)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in f2(a = 10): object 'b' not found\n```\n\n\n:::\n:::\n\n\n::: callout-tip\nSolution: always make sure any required variables are passed as arguments to your functions.\n:::\n\n## Creating our user-built functions\n\nBack to our data preprocessing.\n\nNow that we've got all the information required in a single tibble, we **can build a function that can use that information to calculate and return the latitude and longitude for each individual.**\n\nWe can **use function `destPoint` form package `geosphere` to calculate the destination latitude and longitude from a given starting point, the distance travelled and the direction (bearing) travelled in.**\n\nI our case:\n\n- the distance travelled is equivalent to `stemDistance`.\n- the direction or bearing is equivalent to `stemAzimuth`.\n= the starting point is given by `decimalLatitude` and `decimalLongitude`.\n\nNow, **let's write a function that takes these columns as inputs and returns the latitude and longitude of the location of our individuals.**\n\n### Storing and sourcing functions\n\nFunctions **should be defined in separate `.R` file(s) and stored in the `R/` directory in the root of any project**. \n\nFunction file(s) **should be sourced at the beginning of your analysis script** to make the functions available for use.\n\nWe can **use function `usethis::use_r()` to create scripts in `R/`.** Let's create a new one to start working on our function. Let's call the script containing iur function `geolocate.R`.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nusethis::use_r(\"geolocate\")\n```\n:::\n\n\n``` r\n✔ Setting active project to '/cloud/project'\n✔ Creating 'R/'\n• Modify 'R/geolocate.R'\n```\n\nThis **creates the required `R/` directory** if it doesn't already exist, **creates a new R script named `geolocate.R`** within it and **launches it for editing** all in one go! Nice.\n\n## Experimenting\n\nNow before we begin writing our function, **let's test `destPoint` out**. To do that, **let's subset a single row from `individual` and use it to test out the function.** \n\nWe **need to supply a vector of length two, containing the starting longitude and latitude to argument `p`.** \n\nWe **pass `stemAzimuth` to argument `b`** (for bearing) and **`stemDistance` to argument `d`** (for distance).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- individual[1, ]\ngeosphere::destPoint(\n  p = c(x$decimalLongitude, x$decimalLatitude),\n  b = x$stemAzimuth, d = x$stemDistance\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           lon      lat\n[1,] -71.28333 44.06151\n```\n\n\n:::\n:::\n\n\nThis looks like it's working nicely. Let's also check that it **vectorises properly, i.e. that if we give it vectors of values instead of single ones that it works as expected**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- individual[1:5, ]\n\ngeosphere::destPoint(\n  p = c(x$decimalLongitude, x$decimalLatitude),\n  b = x$stemAzimuth, d = x$stemDistance\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in .pointsToMatrix(p): Wrong length for a vector, should be 2\n```\n\n\n:::\n:::\n\n\nIt looks like it doesn't work by jsut combining longitude and latitude vectors. We need to find a way to vectorise it. To do so, **instead of passing values of `decimalLongitude` and `decimalLongitude` combined into one long vector** with `c()` to `p`, we can **use `cbind()` instead to pass a matrix with two columns**, one for each coordinate.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngeosphere::destPoint(\n  p = cbind(x$decimalLongitude, x$decimalLatitude),\n  b = x$stemAzimuth, d = x$stemDistance\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           lon      lat\n[1,] -71.28333 44.06151\n[2,] -71.28325 44.06165\n[3,] -71.28419 44.06109\n[4,] -71.28424 44.06096\n[5,] -71.28409 44.06103\n```\n\n\n:::\n:::\n\n\nExcellent! **I now get a two dimensional matrix of with two columns and a row for each input element!** This is looking promising.\n\nWe're ready to start writing our function.\n\n## Developing our own functions\n\nLet's start by using a **handy feature in Rstudio, code snippets**. Code snippets are text macros that are used for quickly inserting common snippets of code.\n\nTo initiate the creation of any function in RStudio, we can **start by typing `fun`**. Rstudio's auto-complete should then propose the **function creation snippet**.\n\nPress `Return` to accept the snippet which creates the following template:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nname <- function(variables) {\n\n}\n```\n:::\n\n\nFirst lets start with a descriptive name:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(variables) {\n\n}\n```\n:::\n\n\nLet's add our arguments:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(decimalLongitude, decimalLatitude,\n                              stemAzimuth, stemDistance) {\n\n}\n```\n:::\n\n\nFinally, let's populate the body our our function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  )\n}\n```\n:::\n\n\nLet's also convert the output to a tibble, for better printing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  ) |>\n    tibble::as_tibble()\n}\n```\n:::\n\n\nNote, I'm using the base pipe `|>` here, as it does not require any packages to be loaded to work.\n\n\nNow let's test it out with vectors from `individual`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- get_stem_location(\n  x$decimalLongitude, x$decimalLatitude,\n  x$stemAzimuth, x$stemDistance\n)\ntest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n    lon   lat\n  <dbl> <dbl>\n1 -71.3  44.1\n2 -71.3  44.1\n3 -71.3  44.1\n4 -71.3  44.1\n5 -71.3  44.1\n```\n\n\n:::\n:::\n\n\nLooks like it works nicely!\n\n### Defensive programming in functions\n\nOur function seems to be working correctly but **it's good to incorporate runtime checks, especially on our inputs and outputs**. \n\nFor example, if we supply a character vector to our function by mistake, our function won't work.\n\nWe can **add concise checks using the suite of functions in package `checkmate`.**\n\nOne such function is **`assert_numeric()`.**\n\nThis **checks whether the object we give it is numeric**. \n\n**If the check is successful, it returns the object invisibly. If the check is not successful, it throws an error.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckmate::assert_numeric(x$decimalLatitude)\ncheckmate::assert_numeric(x$uid)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in eval(expr, envir, enclos): Assertion on 'x$uid' failed: Must be of type 'numeric', not 'character'.\n```\n\n\n:::\n:::\n\n\n\n::: callout-tip\n\nThere are two other versions, `test_numeric` which returns `FALSE` if the check is not successful, and `check_numeric` which returns a string with the error message. We want to throw an error and stop execution so we use `assert_numeric`.\n\n:::\n\n**Let's add a validation check for each argument in our function.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  # input validation checks\n  checkmate::assert_numeric(decimalLongitude)\n  checkmate::assert_numeric(decimalLatitude)\n  checkmate::assert_numeric(stemAzimuth)\n  checkmate::assert_numeric(stemDistance)\n\n\n  geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  ) %>%\n    tibble::as_tibble()\n}\n```\n:::\n\n\n**Let's also add a check to our output.** \n\nLet's throw a warning if there are any `NA` values in our output.\n\nFirst we store our output so we can evaluate it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  # input validation checks\n  checkmate::assert_numeric(decimalLongitude)\n  checkmate::assert_numeric(decimalLatitude)\n  checkmate::assert_numeric(stemAzimuth)\n  checkmate::assert_numeric(stemDistance)\n\n\n  out <- geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  ) %>%\n    tibble::as_tibble()\n}\n```\n:::\n\n\nNext we can add our check:\n\nWe can check the whole tibble for `NA`s in one go. We get a 2 dimensional matrix of logical values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nis.na(test) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       lon   lat\n[1,] FALSE FALSE\n[2,] FALSE FALSE\n[3,] FALSE FALSE\n[4,] FALSE FALSE\n[5,] FALSE FALSE\n```\n\n\n:::\n:::\n\n\nWe can then wrap the output of that in `any()` which tests whether there are any `TRUE` values in a logical array.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nany(is.na(test))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\nLet's apply that to our function and use `checkmate::assert_false` to assrt our expectation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  # input validation checks\n  checkmate::assert_numeric(decimalLongitude)\n  checkmate::assert_numeric(decimalLatitude)\n  checkmate::assert_numeric(stemAzimuth)\n  checkmate::assert_numeric(stemDistance)\n\n\n  out <- geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  ) %>%\n    tibble::as_tibble()\n\n  # check output for NAs\n  checkmate::assert_false(any(is.na(out)))\n}\n```\n:::\n\n\nLastly, **we need to return our actual output!**\n\nWe'll add a `return()` statement to do that.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  # input validation checks\n  checkmate::assert_numeric(decimalLongitude)\n  checkmate::assert_numeric(decimalLatitude)\n  checkmate::assert_numeric(stemAzimuth)\n  checkmate::assert_numeric(stemDistance)\n\n\n  out <- geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  ) %>%\n    tibble::as_tibble()\n\n  # check output for NAs\n  checkmate::assert_false(any(is.na(out)))\n\n  return(out)\n}\n```\n:::\n\n\nLet's test it again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_stem_location(\n  x$decimalLongitude, x$decimalLatitude,\n  x$stemAzimuth, x$stemDistance\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n    lon   lat\n  <dbl> <dbl>\n1 -71.3  44.1\n2 -71.3  44.1\n3 -71.3  44.1\n4 -71.3  44.1\n5 -71.3  44.1\n```\n\n\n:::\n:::\n\n\n\n### Add documentation\n\nFinally, we can add documentation to our function using `roxygen` notation. This should describe what the function does, what arguments it accepts, and what it returns.\n\nTo insert a roxygen skeleton, we can place the cursor anywhere within the function definition and press `Alt + Ctrl + Shift + R` (Windows/Linux) or `Cmd + Shift + Option + R` (Mac) or select **Code \\> Insert Roxygen Skeleton** from the In RStudio drop down menu:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Title\n#'\n#' @param decimalLongitude\n#' @param decimalLatitude\n#' @param stemAzimuth\n#' @param stemDistance\n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  # input validation checks\n  checkmate::assert_numeric(decimalLongitude)\n  checkmate::assert_numeric(decimalLatitude)\n  checkmate::assert_numeric(stemAzimuth)\n  checkmate::assert_numeric(stemDistance)\n\n\n  out <- geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  ) %>%\n    tibble::as_tibble()\n\n  # check output for NAs\n  checkmate::assert_false(any(is.na(out)))\n\n  return(out)\n}\n```\n:::\n\n\nThis inserts a template for the documentation of the function. We can now fill in the title, definition of our arguments through `@param` and return value through `@return`. \n\nLet's just delete the `@examples` and `@return` section and complete the rest of the fields:\n\n-  **Title**: A brief description of what the function does.\n-  **@param**: A description of each argument the function accepts.\n-  **@return**: A description of what the function returns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Calculate the location of a stem based on azimuth and distance\n#'\n#' @param decimalLongitude numeric vector of decimal longitudes\n#' @param decimalLatitude numeric vector of decimal latitudes\n#' @param stemAzimuth numeric vector of stem azimuths\n#' @param stemDistance numeric vector of stem distances\n#'\n#' @return A tibble of pairs of coordinates\nget_stem_location <- function(decimalLongitude, decimalLatitude, \n                              stemAzimuth, stemDistance) {\n  # input validation checks\n  checkmate::assert_numeric(decimalLongitude)\n  checkmate::assert_numeric(decimalLatitude)\n  checkmate::assert_numeric(stemAzimuth)\n  checkmate::assert_numeric(stemDistance)\n\n\n  out <- geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth, d = stemDistance\n  ) %>%\n    tibble::as_tibble()\n\n  # check output for NAs\n  checkmate::assert_false(any(is.na(out)))\n\n  return(out)\n}\n```\n:::\n\n\nAdding this documentation will make it easier for others (and ourselves) to understand what the function does and how to use it.\n\nAnd now, remove any excess code from our script and save.\n\nOur function is now **ready to be sourced** and made available for use in **our last preprocessing stage, adding the new `stemLat` and `stemLon` columns**. :tada:.\n\n## Sourcing our function in `individual.R`\n\nLet's **move back to our `individual.R` script**. \n\nAt the top of our script, let's **add the code to source our function so it's available during preprocessing**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(here::here(\"R\", \"geolocate.R\"))\n```\n:::\n\n\n## Adding stem geolocation to `individual`\n\n### Making new variables with `mutate`\n\nNow we want to **use data in `individual` to geolocate our individuals** while at the same time **create two new columns `stemLat` and `stemLon`**.\n\nFor this we **use `dplyr::mutate()`**. This function is **used to modify or add new variables** to a data frame. \n\nWe also need to **extract the appropriate coordinate for each column from the output of `get_stem_location()`**. We do that by using the `$` subsetting operation after we call `get_stem_location()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindividual %>% mutate(\n  stemLat = get_stem_location(\n    decimalLongitude, decimalLatitude,\n    stemAzimuth, stemDistance\n  )$lat,\n  stemLon = get_stem_location(\n    decimalLongitude, decimalLatitude,\n    stemAzimuth, stemDistance\n  )$lon\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 14,961 × 32\n   uid      namedLocation date       eventID domainID siteID plotID individualID\n   <chr>    <chr>         <date>     <chr>   <chr>    <chr>  <chr>  <chr>       \n 1 a36a162… BART_037.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 2 68dc7ad… BART_037.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 3 a8951ab… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 4 eb348ea… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 5 2a4478e… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 6 e485203… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 7 280c904… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 8 0e5060e… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n 9 4918cac… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n10 ef16cb9… BART_044.bas… 2015-08-26 vst_BA… D01      BART   BART_… NEON.PLA.D0…\n# ℹ 14,951 more rows\n# ℹ 24 more variables: growthForm <chr>, stemDiameter <dbl>,\n#   measurementHeight <dbl>, height <dbl>, uid_map <chr>, pointID <dbl>,\n#   stemDistance <dbl>, stemAzimuth <dbl>, taxonID <chr>, scientificName <chr>,\n#   taxonRank <chr>, uid_ppl <chr>, plotType <chr>, nlcdClass <chr>,\n#   decimalLatitude <dbl>, decimalLongitude <dbl>, geodeticDatum <chr>,\n#   easting <dbl>, northing <dbl>, utmZone <chr>, elevation <dbl>, …\n```\n\n\n:::\n:::\n\n\n\nIt works! We're almost done with our data munging!\n\nLets *assign the output back to `individual`.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindividual <- individual %>%\n  mutate(\n    stemLat = get_stem_location(\n      decimalLongitude, decimalLatitude,\n      stemAzimuth, stemDistance\n    )$lat,\n    stemLon = get_stem_location(\n      decimalLongitude, decimalLatitude,\n      stemAzimuth, stemDistance\n    )$lon\n  )\n```\n:::\n\n\nLet's do a couple last sanity checks:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nView(individual)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(individual)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nspc_tbl_ [14,961 × 32] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ uid                 : chr [1:14961] \"a36a162d-ed1f-4f80-ae45-88e973855c68\" \"68dc7adf-48e2-4f7a-9272-9a468fde6d55\" \"a8951ab9-4462-48dd-ab9e-7b89e24f2e03\" \"eb348eaf-3969-46a4-ac3b-523c3548efeb\" ...\n $ namedLocation       : chr [1:14961] \"BART_037.basePlot.vst\" \"BART_037.basePlot.vst\" \"BART_044.basePlot.vst\" \"BART_044.basePlot.vst\" ...\n $ date                : Date[1:14961], format: \"2015-08-26\" \"2015-08-26\" ...\n $ eventID             : chr [1:14961] \"vst_BART_2015\" \"vst_BART_2015\" \"vst_BART_2015\" \"vst_BART_2015\" ...\n $ domainID            : chr [1:14961] \"D01\" \"D01\" \"D01\" \"D01\" ...\n $ siteID              : chr [1:14961] \"BART\" \"BART\" \"BART\" \"BART\" ...\n $ plotID              : chr [1:14961] \"BART_037\" \"BART_037\" \"BART_044\" \"BART_044\" ...\n $ individualID        : chr [1:14961] \"NEON.PLA.D01.BART.05285\" \"NEON.PLA.D01.BART.05279\" \"NEON.PLA.D01.BART.05419\" \"NEON.PLA.D01.BART.05092\" ...\n $ growthForm          : chr [1:14961] \"single bole tree\" \"single bole tree\" \"single bole tree\" \"single bole tree\" ...\n $ stemDiameter        : num [1:14961] 17.1 13.7 12.3 12.1 29.2 12.1 23.4 39.5 10 10.6 ...\n $ measurementHeight   : num [1:14961] 130 130 130 130 130 130 130 130 130 130 ...\n $ height              : num [1:14961] 15.2 9.8 7.7 15.2 16.7 10.6 18.4 19 5.7 8.7 ...\n $ uid_map             : chr [1:14961] \"31c5ffdb-25cb-474c-b34b-c88ddf520dc2\" \"a59c6688-ef88-46bb-979d-ba23b6e84d1a\" \"64a921b6-ce50-442e-8811-40e6c086c99e\" \"f6cba56b-b14f-42e0-ab20-06e2bfa216d2\" ...\n $ pointID             : num [1:14961] 61 41 23 57 57 23 57 41 57 57 ...\n $ stemDistance        : num [1:14961] 11.3 6.1 12 11.5 19 7 7.4 6.4 12.7 15.1 ...\n $ stemAzimuth         : num [1:14961] 212.1 4 62.1 140.8 93 ...\n $ taxonID             : chr [1:14961] \"ACRU\" \"FAGR\" \"TSCA\" \"FAGR\" ...\n $ scientificName      : chr [1:14961] \"Acer rubrum L.\" \"Fagus grandifolia Ehrh.\" \"Tsuga canadensis (L.) Carrière\" \"Fagus grandifolia Ehrh.\" ...\n $ taxonRank           : chr [1:14961] \"species\" \"species\" \"species\" \"species\" ...\n $ uid_ppl             : chr [1:14961] \"5ac133b6-1089-4f32-9c26-27c3fd6b2597\" \"5ac133b6-1089-4f32-9c26-27c3fd6b2597\" \"c4207c9a-028a-4a26-a4ee-5d1a70df1e66\" \"c4207c9a-028a-4a26-a4ee-5d1a70df1e66\" ...\n $ plotType            : chr [1:14961] \"tower\" \"tower\" \"tower\" \"tower\" ...\n $ nlcdClass           : chr [1:14961] \"deciduousForest\" \"deciduousForest\" \"deciduousForest\" \"deciduousForest\" ...\n $ decimalLatitude     : num [1:14961] 44.1 44.1 44.1 44.1 44.1 ...\n $ decimalLongitude    : num [1:14961] -71.3 -71.3 -71.3 -71.3 -71.3 ...\n $ geodeticDatum       : chr [1:14961] \"WGS84\" \"WGS84\" \"WGS84\" \"WGS84\" ...\n $ easting             : num [1:14961] 317130 317130 317042 317042 317042 ...\n $ northing            : num [1:14961] 4881249 4881249 4881189 4881189 4881189 ...\n $ utmZone             : chr [1:14961] \"19N\" \"19N\" \"19N\" \"19N\" ...\n $ elevation           : num [1:14961] 292 292 303 303 303 ...\n $ elevationUncertainty: num [1:14961] 0.2 0.2 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 ...\n $ stemLat             : num [1:14961] 44.1 44.1 44.1 44.1 44.1 ...\n $ stemLon             : num [1:14961] -71.3 -71.3 -71.3 -71.3 -71.3 ...\n - attr(*, \"spec\")=List of 3\n  ..$ cols   :List of 12\n  .. ..$ uid              : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ namedLocation    : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ date             :List of 1\n  .. .. ..$ format: chr \"\"\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_date\" \"collector\"\n  .. ..$ eventID          : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ domainID         : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ siteID           : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ plotID           : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ individualID     : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ growthForm       : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_character\" \"collector\"\n  .. ..$ stemDiameter     : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_double\" \"collector\"\n  .. ..$ measurementHeight: list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_double\" \"collector\"\n  .. ..$ height           : list()\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"collector_double\" \"collector\"\n  ..$ default: list()\n  .. ..- attr(*, \"class\")= chr [1:2] \"collector_guess\" \"collector\"\n  ..$ delim  : chr \",\"\n  ..- attr(*, \"class\")= chr \"col_spec\"\n - attr(*, \"problems\")=<externalptr> \n```\n\n\n:::\n:::\n\n\nAnd save our  `individual.R`  file.\n\n## Saving analytical data\n\nAt the bottom of `individual.R` there is some template code, `usethis::use_data(\"individual\")`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nusethis::use_data(\"individual\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ Setting active project to\n'/Users/Anna/Documents/workflows/workshops/rrresearch-acce-rrse'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-error}\n\n```\nError: `use_data()` is designed to work with packages.\nProject 'rrresearch-acce-rrse' is not an R package.\n```\n\n\n:::\n:::\n\n\nThis functions invokes functionality to **store an R object as an `.Rdata` binary file** (i.e. as a tibble not a `csv`) in the `data` directory. This is the standard way to store exported data in packages but **given it's an R specific format, it is less FAIR than if we saved the data as a simple csv.**\n\n`use_data()` is also designed to be used in packages and doesn't work outside that context.\n\nLet's **just get rid of it and instead, save our analytic data as a csv in our `data` directory instead.**\n\nFirst lets **create a data directory.** \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfs::dir_create(\"data\")\n```\n:::\n\n\nNow were ready to write or data out. \n\nBefore we do so, I will add one last touch. I would like to **get rid of** a pet hate of mine, and that's **`camelCase` variable names!**\n\nIn general, it's **more common to use `snake_case` for names in R.** \n\nTo do this I use a **handy function `clean_names()` in package `janitor` which will check and clean column names and convert them to snake case !**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindividual %>%\n  janitor::clean_names()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 14,961 × 32\n   uid              named_location date       event_id domain_id site_id plot_id\n   <chr>            <chr>          <date>     <chr>    <chr>     <chr>   <chr>  \n 1 a36a162d-ed1f-4… BART_037.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 2 68dc7adf-48e2-4… BART_037.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 3 a8951ab9-4462-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 4 eb348eaf-3969-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 5 2a4478ef-5970-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 6 e485203e-879e-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 7 280c9049-1915-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 8 0e5060ec-a6d8-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n 9 4918cac0-62fb-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n10 ef16cb9c-0b68-4… BART_044.base… 2015-08-26 vst_BAR… D01       BART    BART_0…\n# ℹ 14,951 more rows\n# ℹ 25 more variables: individual_id <chr>, growth_form <chr>,\n#   stem_diameter <dbl>, measurement_height <dbl>, height <dbl>, uid_map <chr>,\n#   point_id <dbl>, stem_distance <dbl>, stem_azimuth <dbl>, taxon_id <chr>,\n#   scientific_name <chr>, taxon_rank <chr>, uid_ppl <chr>, plot_type <chr>,\n#   nlcd_class <chr>, decimal_latitude <dbl>, decimal_longitude <dbl>,\n#   geodetic_datum <chr>, easting <dbl>, northing <dbl>, utm_zone <chr>, …\n```\n\n\n:::\n:::\n\n\n\nNow, with that final tweak, **let's add the `readr::write_csv` function to save our data as `individual.csv` into the `data` directory.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindividual %>%\n  janitor::clean_names() %>%\n  readr::write_csv(here::here(\"data\", \"individual.csv\"))\n```\n:::\n\n\n## Final processing script:\n\nThis what our final `data-raw/individual.R` script should look like:\n\n\n::: {.cell filename='data-raw/individual.R'}\n\n```{.r .cell-code}\n## code to prepare `individual` dataset goes here\n## Setup\nlibrary(dplyr)\nsource(here::here(\"R\", \"geolocate.R\"))\n\n## Combine individual tables ----\n# Create paths to inputs\nraw_data_path <- here::here(\"data-raw\", \"wood-survey-data-master\")\nindividual_paths <- fs::dir_ls(fs::path(raw_data_path, \"individual\"))\n\n# read in all individual tables into one\nindividual <- purrr::map(\n  individual_paths,\n  ~ readr::read_csv(\n    file = .x,\n    col_types = readr::cols(.default = \"c\"),\n    show_col_types = FALSE\n  )\n) %>%\n  purrr::list_rbind() %>%\n  readr::type_convert()\n\nindividual %>%\n  readr::write_csv(file = fs::path(raw_data_path, \"vst_individuals.csv\"))\n\n# Combine NEON data tables ----\n# read in additional table\nmaptag <- readr::read_csv(\n  fs::path(\n    raw_data_path,\n    \"vst_mappingandtagging.csv\"\n  ),\n  show_col_types = FALSE\n) %>%\n  select(-eventID)\n\nperplot <- readr::read_csv(\n  fs::path(\n    raw_data_path,\n    \"vst_perplotperyear.csv\"\n  ),\n  show_col_types = FALSE\n) %>%\n  select(-eventID)\n\n# Left join tables to individual\nindividual %<>%\n  left_join(maptag,\n    by = \"individualID\",\n    suffix = c(\"\", \"_map\")\n  ) %>%\n  left_join(perplot,\n    by = \"plotID\",\n    suffix = c(\"\", \"_ppl\")\n  ) %>%\n  assertr::assert(\n    assertr::not_na, stemDistance, stemAzimuth, pointID,\n    decimalLongitude, decimalLatitude, plotID\n  )\n\n# ---- Geolocate individuals_functions ----\nindividual <- individual %>%\n  mutate(\n    stemLat = get_stem_location(\n      decimalLongitude = decimalLongitude,\n      decimalLatitude = decimalLatitude,\n      stemAzimuth = stemAzimuth,\n      stemDistance = stemDistance\n    )$lat,\n    stemLon = get_stem_location(\n      decimalLongitude = decimalLongitude,\n      decimalLatitude = decimalLatitude,\n      stemAzimuth = stemAzimuth,\n      stemDistance = stemDistance\n    )$lon\n  )\n\n# create data directory\nfs::dir_create(here::here(\"data\"))\n\n# write out analytic file\nindividual %>%\n  janitor::clean_names() %>%\n  readr::write_csv(here::here(\"data\", \"individual.csv\"))\n```\n:::\n\n\n## Final function script:\n\nand this is what our final `R/geolocate.R` should look like:\n\n\n\n::: {.cell filename='R/geolocate.R'}\n\n```{.r .cell-code}\n#' Calculate the location of a stem based on azimuth and distance\n#'\n#' @param decimalLongitude numeric vector of decimal longitudes\n#' @param decimalLatitude numeric vector of decimal latitudes\n#' @param stemAzimuth numeric vector of stem azimuths\n#' @param stemDistance numeric vector of stem distances\n#'\n#' @return A tibble of pairs of coordinates\nget_stem_location <- function(decimalLongitude, decimalLatitude,\n                              stemAzimuth, stemDistance) {\n  # input validation checks\n  checkmate::assert_numeric(decimalLatitude)\n  checkmate::assert_numeric(decimalLongitude)\n  checkmate::assert_numeric(stemAzimuth)\n  checkmate::assert_numeric(stemDistance)\n\n\n  out <- geosphere::destPoint(\n    p = cbind(decimalLongitude, decimalLatitude),\n    b = stemAzimuth,\n    d = stemDistance\n  ) |>\n    tibble::as_tibble()\n\n  # check output for NAs\n  checkmate::assert_false(any(is.na(out)))\n\n  return(out)\n}\n```\n:::\n\n\n## Run the preprocessing script\n\nOur `individual.R` preprocessing script is now complete and **represents a clean reproducible workflow for processing our raw data into a single analytical data set.**\n\nSo let's **clean our environment and run the entire script, from top to bottom, to ensure everytyhing works and to generate our final data set.**\n",
    "supporting": [
      "03c_functions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}